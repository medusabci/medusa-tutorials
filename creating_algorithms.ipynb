{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Welcome to algorithm creation tutorial!\n",
    "\n",
    "The Algorithm class is a powerful tool that provides common ground for data\n",
    "processing pipelines as well as persistence functionalities. This notebook will\n",
    "cover the main features, functions and classes involved in the definition of\n",
    "an algorithm through illustrative examples.\n",
    "\n",
    "In this notebook you will learn:\n",
    "    - What is the ProcessingMethod class\n",
    "    - Wrap functions and external classes in the ProcessingMethod class\n",
    "    - Define a processing pipeline\n",
    "    - Use the Algorithm class\n",
    "\n",
    "Do not forget to check the documentation if you do not understand something!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "Medusa has been designed to facilitate the implementation of signal processing\n",
    "algorithms meeting the needs of researchers and developers from different\n",
    "fields. This includes not only the implementation of cutting-edge ready-to-use\n",
    "signal processing methods, but also high level features to assure the\n",
    "persistence and reproducibility of the algorithms created within medusa. All of\n",
    "this, assuring interoperability with existing frameworks such as sklearn,\n",
    "tensorflow, mne, etc. The Algorithm class meets these requirements, providing\n",
    "a novel methodology to create, save and share complex data processing\n",
    "algorithms."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports\n",
    "\n",
    "Import the modules that will be used in this notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%% cd\n"
    }
   },
   "outputs": [],
   "source": [
    "# General imports\n",
    "import numpy as np\n",
    "\n",
    "# External processing methods\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "\n",
    "# Medusa imports\n",
    "import medusa.components as mds_cmp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data\n",
    "\n",
    "First, we will create some data, simulating a set of features extracted from a\n",
    "biosignal recording with the corresponding labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%% cd\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set: \n",
      "\tX shape: (200, 5)\n",
      "\ty shape: (200,)\n",
      "Test set: \n",
      "\tX shape: (10, 5)\n",
      "\ty shape: (10,)\n",
      "\n",
      "Test labels: [1. 1. 1. 1. 1. 0. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "# Create train dataset\n",
    "x_train = np.random.rand(1000).reshape((200, 5))\n",
    "x_train[:100, :] = x_train[:100, :] + 1\n",
    "x_train[100:, :] = x_train[100:, :] - 1\n",
    "\n",
    "y_train = np.zeros((200,))\n",
    "y_train[:100] = 1\n",
    "\n",
    "# Create test dataset\n",
    "x_test = np.random.rand(50).reshape((10, 5))\n",
    "x_test[:5, :] = x_test[:5, :] + 1\n",
    "x_test[5:, :] = x_test[5:, :] - 1\n",
    "\n",
    "y_test = np.zeros((10,))\n",
    "y_test[:5] = 1\n",
    "\n",
    "print('Train set: ')\n",
    "print('\\tX shape: %s' % str(x_train.shape))\n",
    "print('\\ty shape: %s' % str(y_train.shape))\n",
    "\n",
    "print('Test set: ')\n",
    "print('\\tX shape: %s' % str(x_test.shape))\n",
    "print('\\ty shape: %s' % str(y_test.shape))\n",
    "\n",
    "print()\n",
    "print('Test labels: %s' % str(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Processing methods\n",
    "\n",
    "The next step is to instantiate the methods that will compose the algorithm.\n",
    "Only methods that inherit from medusa.components.ProcessingMethod can be added\n",
    "to the Algorithm class. Medusa framework includes a wide variety of signal\n",
    "processing methods ready to use. Nevertheless, function and class wrappers\n",
    "have been designed to assure full interoperability with external packages.\n",
    "\n",
    "To show these functionalities, we will implement 2 versions of the linear\n",
    "discriminant analysis (LDA) using the sklearn package. First, we will implement\n",
    "a function to scale the data, just to show how to use ProcessingFuncWrapper.\n",
    "Afterwards, we will use the class ProcessingClassWrapper to wrap the LDA class\n",
    "in ProcessingMethod. Finally, we will design our own wrapper for the sklearn\n",
    "class subclassing ProcessingMethod directly. Both methods must have the same\n",
    "results. In practice, the second way is preferred over the use of\n",
    "ProcessingClassWrapper, because, in very rare occasions, the automatic attribute\n",
    "inheritance may cause unexpected problems.\n",
    "\n",
    "An important issue is the definition of the functions that will be exposed to\n",
    "the algorithm for each processing method. Class Algorithm needs to know which\n",
    "functions of each method can be executed, and what are the outputs. We will have\n",
    "to define these parameters in the constructors of ProcessingFuncWrapper,\n",
    "ProcessingClassWrapper and ProcessingMethod. Be careful, these definitions will\n",
    "be used later to compile the processing pipelines!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%% cd\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK!\n"
     ]
    }
   ],
   "source": [
    "# 1. Data scaler\n",
    "def scale(x, n):\n",
    "    return n * x\n",
    "scaler = mds_cmp. ProcessingFuncWrapper(scale, outputs=['x'])\n",
    "\n",
    "# 2. LDA classifier from sklearn using ProcessingClassWrapper\n",
    "lda1 = mds_cmp.ProcessingClassWrapper(LinearDiscriminantAnalysis(),\n",
    "                                      fit=[], predict=['y'])\n",
    "\n",
    "# 3. Wrapper for sklearn LDA classifier\n",
    "class LDAWrapper(mds_cmp.ProcessingMethod):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__(fit=[], predict=['y'])\n",
    "        self.clf = LinearDiscriminantAnalysis()\n",
    "\n",
    "    def fit(self, x, y):\n",
    "        self.clf.fit(x, y)\n",
    "\n",
    "    def predict(self, x):\n",
    "        return self.clf.predict(x)\n",
    "\n",
    "lda2 = LDAWrapper()\n",
    "\n",
    "print('OK!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Instantiate algorithm\n",
    "\n",
    "Once the methods have been instantiated, we will create the algorithm and add\n",
    "them, specifying a unique id for each one of them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%% cd\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK!\n"
     ]
    }
   ],
   "source": [
    "# Algorithm\n",
    "alg = mds_cmp.Algorithm()\n",
    "\n",
    "# Add methods\n",
    "alg.add_method('scaler', scaler)\n",
    "alg.add_method('lda1', lda1)\n",
    "alg.add_method('lda2', lda2)\n",
    "\n",
    "print('OK!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Design the processing pipelines\n",
    "\n",
    "An algorithm can have several processing pipelines that can be executed\n",
    "independently. Some usage examples are the fit and apply stages of the\n",
    "methods, or the splitting of the algorithm in several independent stages\n",
    "(e.g., preprocessing, feature extraction, feature selection and feature\n",
    "classification). Therefore, the Algorithm class provides high flexibility to\n",
    "meet the needs of researchers and developers. Remember that the pipeline\n",
    "doesn't check the consistency of the connections. This will be done by the\n",
    "algorithm, which compiles the pipeline on fly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%% cd\n"
    }
   },
   "outputs": [],
   "source": [
    "# Train pipe\n",
    "train_pipe = mds_cmp.Pipeline()\n",
    "uid_0 = train_pipe.input(['x', 'y'])\n",
    "uid_1 = train_pipe.add(method_func_key='scaler:scale',\n",
    "                       x=train_pipe.conn_to(uid_0, 'x'), n=2)\n",
    "uid_2 = train_pipe.add(method_func_key='lda1:fit',\n",
    "                       X=train_pipe.conn_to(uid_0, 'x'),\n",
    "                       y=train_pipe.conn_to(uid_0, 'y'))\n",
    "uid_3 = train_pipe.add(method_func_key='lda2:fit',\n",
    "                       x=train_pipe.conn_to(uid_1, 'x'),\n",
    "                       y=train_pipe.conn_to(uid_0, 'y'))\n",
    "\n",
    "# Test pipe\n",
    "test_pipe = mds_cmp.Pipeline()\n",
    "uid_0 = test_pipe.input(['x'])\n",
    "uid_1 = test_pipe.add(method_func_key='scaler:scale',\n",
    "                      x=test_pipe.conn_to(uid_0, 'x'), n=2)\n",
    "uid_2 = test_pipe.add(method_func_key='lda1:predict',\n",
    "                      X=test_pipe.conn_to(uid_1, 'x'))\n",
    "uid_3 = test_pipe.add(method_func_key='lda2:predict',\n",
    "                      x=test_pipe.conn_to(uid_1, 'x'))\n",
    "\n",
    "\n",
    "# Add pipelines\n",
    "alg.add_pipeline('train', train_pipe)\n",
    "alg.add_pipeline('test', test_pipe)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Execute pipelines\n",
    "\n",
    "Now, we will execute the pipelines. To do this, just call to exec_pipeline\n",
    "method of Algorithm, providing the correct input keys and values. Remember\n",
    "that the algorithm maintains the state between executions, so we can fit and\n",
    "test the implemented classifiers.\n",
    "\n",
    "Function exec_pipeline returns 2 tuples. The first tuple contains the processing\n",
    "method that has been applied in each step of the algorithm. The second tuple\n",
    "contains the results of these steps, assigned to each of the exposed outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%% cd\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished 'exec_pipeline' in 0.0041 secs\n",
      "Finished 'exec_pipeline' in 0.0005 secs\n",
      "\n",
      "Prediction of LDA 1: [1. 1. 1. 1. 1. 0. 0. 0. 0. 0.]\n",
      "Prediction of LDA 2: [1. 1. 1. 1. 1. 0. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "# Execute pipelines\n",
    "train_res_keys, train_res_val = alg.exec_pipeline('train', x=x_train, y=y_train)\n",
    "test_res_keys, test_res_val = alg.exec_pipeline('test', x=x_test)\n",
    "\n",
    "print()\n",
    "print('Prediction of LDA 1: %s' % str(test_res_val[2]['y']))\n",
    "print('Prediction of LDA 2: %s' % str(test_res_val[3]['y']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Persistence\n",
    "\n",
    "The Algorithm class includes persistence options to save the algorithm in\n",
    "the current state. Execute the next cell to save and load the previous\n",
    "algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%% cd\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished 'exec_pipeline' in 0.0002 secs\n",
      "\n",
      "Prediction of LDA 1: [1. 1. 1. 1. 1. 0. 0. 0. 0. 0.]\n",
      "Prediction of LDA 2: [1. 1. 1. 1. 1. 0. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "# Save algorithm\n",
    "alg.save('alg.pkl')\n",
    "\n",
    "# Load algorithm\n",
    "loaded_alg = mds_cmp.Algorithm.load('alg.pkl')\n",
    "test_res_keys, test_res_val = loaded_alg.exec_pipeline('test', x=x_test)\n",
    "\n",
    "print()\n",
    "print('Prediction of LDA 1: %s' % str(test_res_val[2]['y']))\n",
    "print('Prediction of LDA 2: %s' % str(test_res_val[3]['y']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Conclusion\n",
    "\n",
    "That's all for now! Now you have a comprehensive picture of the functions and\n",
    "classes involved in the creation of medusa algorithms. As you can see, you can\n",
    "build full signal processing pipelines in a very flexible and easy way with\n",
    "few code lines using Medusa!\n",
    "\n",
    "See you in the next tutorial."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}