{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Welcome to the overview of medusa.bci.erp_spellers module!\n",
    "\n",
    "This module contains high level classes and functions specifically designed\n",
    "for ERP-based spellers. This notebook will cover the main features, functions\n",
    "and classes of the module through illustrative examples which will show you\n",
    "the power of the included tools.\n",
    "\n",
    "In this notebook you will learn:\n",
    "    - What is an ERP-based speller\n",
    "    - Download an open ERP-speller dataset and explore the files\n",
    "    - Create an instance of ERPSpellerDataset\n",
    "    - Know the feature extraction and decoding functions included in the module\n",
    "    - Implement an asynchronous ERP-based speller using the built-in models\n",
    "\n",
    "Do not forget to check the documentation if you do not understand something!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Introduction\n",
    "\n",
    "ERP-based spellers are\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports\n",
    "\n",
    "Import the modules that will be used in this notebook and define auxiliary\n",
    "functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%% cd\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK!\n"
     ]
    }
   ],
   "source": [
    "# General imports\n",
    "import glob\n",
    "from tabulate import tabulate\n",
    "import numpy as np\n",
    "\n",
    "# Medusa imports\n",
    "from medusa import components\n",
    "from medusa import meeg\n",
    "from medusa.bci import erp_spellers\n",
    "\n",
    "def print_acc_per_seq(acc_per_seq):\n",
    "    table_cmd_acc_per_seq = ['Command decoding acc']\n",
    "    cmd_acc_per_seq = np.char.mod('%.2f', acc_per_seq*100).astype(str).tolist()\n",
    "    table_cmd_acc_per_seq += cmd_acc_per_seq\n",
    "    headers = [''] + list(range(1, 16))\n",
    "    print('\\nTrain accuracy per number of sequences of stimulation:\\n')\n",
    "    print(tabulate([table_cmd_acc_per_seq], headers=headers))\n",
    "\n",
    "print('OK!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download the dataset\n",
    "\n",
    "As strong supporters of open science, we have released and adapted some\n",
    "valuable datasets that can be very useful for researchers and practitioners.\n",
    "These datasets can be downloaded manually from www.medusa.com/datasets/ or\n",
    "using a simple API. In this case, we will use the API. Run the following cell\n",
    "to download the GIB-UVa ERP dataset [1].\n",
    "\n",
    "Each file is an instance of medusa.data_structures.Recording. This class\n",
    "contains the information of the performed experiment and the recorded biosignals\n",
    "In this case, the recordings contain an instance of\n",
    "medusa.components.ERPSpellerData, which is the default class for this\n",
    "experiment. Additionally, all recordings contain a medusa.meeg.EEG instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%% cd\n"
    }
   },
   "outputs": [],
   "source": [
    "# TODO: Download dataset\n",
    "# dataset_folder = os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## ERPSpellerDataset class\n",
    "\n",
    "This class is used to define an ERPSpeller dataset, which contains all the\n",
    "necessary information to work with the functions and classes of the module and\n",
    "checks for common errors.\n",
    "\n",
    "First, we have to define the channel set of the dataset. The signals added\n",
    "to the dataset will be adapted to this channel set, discarding the rest of EEG\n",
    "channels. In addition, the channels will be reordered if necessary. This\n",
    "avoids errors in heterogeneous datasets, and, believe me, saves tons of time\n",
    "wasted debugging machine learning algorithms. In this case, we will use 4 EEG\n",
    "channels: Fz, Cz, Pz, and Oz.\n",
    "\n",
    "We also have to define other parameters. The sample rate of the recordings\n",
    "is set to 256 Hz (if a file has different sample rate, it will throw  an error).\n",
    "We also define the keys to find the target biosignal (EEG) and experiment data\n",
    "(ERPSpellerData) attributes in the recording class, a well as the experiment\n",
    "mode, which is  set to train because we will use this dataset to train a\n",
    "model later. Check the documentation to understand the details of this and\n",
    "more parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%% cd\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK!\n"
     ]
    }
   ],
   "source": [
    "cha_set = meeg.EEGChannelSet()\n",
    "cha_set.set_standard_channels(l_cha=['Fz', 'Cz', 'Pz', 'Oz'])\n",
    "dataset = erp_spellers.ERPSpellerDataset(channel_set=cha_set,\n",
    "                                         fs=256,\n",
    "                                         biosignal_att_key='eeg',\n",
    "                                         experiment_att_key='erpspellerdata',\n",
    "                                         experiment_mode='train')\n",
    "\n",
    "print('OK!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Add recordings to the dataset\n",
    "\n",
    "Now, we have to add the recordings to the dataset. With this purpose, we read\n",
    "the files that were downloaded and use the function add_recordings of our\n",
    "dataset. Note that this function admits instances of medusa.components.Recording\n",
    "or a list of paths. For convenience, we will use the second option in this case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%% cd\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK!\n"
     ]
    }
   ],
   "source": [
    "folder = 'data'\n",
    "file_pattern = '*.rcp.bson'\n",
    "files = glob.glob('%s/%s' % (folder, file_pattern))\n",
    "dataset.add_recordings(files)\n",
    "\n",
    "print('OK!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Explore some functions and classes\n",
    "\n",
    "Once we have defined our dataset, we can start to play! First, we extract\n",
    "ERP features using the class StandardFeatureExtraction with default parameters.\n",
    "This class extracts the EEG epochs after each stimulus onset\n",
    "\n",
    "Afterwards, we explore some decoding functions of the module, which translate\n",
    "epoch classification scores into commands,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%% cd\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Data exploration: \n",
      "\n",
      "----------  ----\n",
      "Runs           8\n",
      "Epochs      8640\n",
      "Target      1440\n",
      "Non-target  7200\n",
      "----------  ----\n",
      "Command decoding accuracy: 100.00 %\n",
      "\n",
      "Train accuracy per number of sequences of stimulation:\n",
      "\n",
      "                        1    2    3    4    5    6    7    8    9    10    11    12    13    14    15\n",
      "--------------------  ---  ---  ---  ---  ---  ---  ---  ---  ---  ----  ----  ----  ----  ----  ----\n",
      "Command decoding acc  100  100  100  100  100  100  100  100  100   100   100   100   100   100   100\n"
     ]
    }
   ],
   "source": [
    "# Extract ERP features of the dataset using the transform_dataset function of\n",
    "# StandardFeatureExtraction.\n",
    "feat_extractor = erp_spellers.StandardFeatureExtraction()\n",
    "x, x_info = feat_extractor.transform_dataset(dataset)\n",
    "\n",
    "# Print some info of the extracted features\n",
    "data_exploration = [\n",
    "    ['Runs', np.unique(x_info['run_idx']).shape[0]],\n",
    "    ['Epochs', x.shape[0]],\n",
    "    ['Target', np.sum(x_info['erp_labels']==1)],\n",
    "    ['Non-target', np.sum(x_info['erp_labels']==0)]\n",
    "]\n",
    "print('\\nData exploration: \\n')\n",
    "print(tabulate(data_exploration))\n",
    "\n",
    "# Check the command decoding function. In practice, you would put the\n",
    "# classification scores for the ERP epochs, instead of the erp labels.\n",
    "selected_commands, selected_commands_per_seq, cmd_scores = \\\n",
    "    erp_spellers.decode_commands(\n",
    "        x_info['erp_labels'],\n",
    "        x_info['paradigm_conf'],\n",
    "        x_info['run_idx'],\n",
    "        x_info['trial_idx'],\n",
    "        x_info['matrix_idx'],\n",
    "        x_info['level_idx'],\n",
    "        x_info['unit_idx'],\n",
    "        x_info['sequence_idx'],\n",
    "        x_info['group_idx'],\n",
    "        x_info['batch_idx']\n",
    "    )\n",
    "\n",
    "# Check this function to calculate the command decoding accuracy\n",
    "cmd_acc = erp_spellers.command_decoding_accuracy(\n",
    "    selected_commands,\n",
    "    x_info['spell_target']\n",
    ")\n",
    "print('Command decoding accuracy: %.2f %%' % (cmd_acc * 100))\n",
    "\n",
    "# Check this function to calculate the command decoding accuracy as a function\n",
    "# of the number of stimulation sequences included in the analysis.\n",
    "cmd_acc_per_seq = erp_spellers.command_decoding_accuracy_per_seq(\n",
    "    selected_commands_per_seq,\n",
    "    x_info['spell_target']\n",
    ")\n",
    "print_acc_per_seq(cmd_acc_per_seq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Command decoding model\n",
    "\n",
    "Although the previous functions are really powerful, and you can build your\n",
    "own EEG processing framework for ERP-based spellers easily with them, there is\n",
    "several built-in classes that combine them all to provide tested models ready to\n",
    "be used in your projects.\n",
    "\n",
    "In this tutorial, we will use some of the most powerful processing algorithms\n",
    "designed to date for ERP-based spellers. Take into account these models\n",
    "implement all the stages of the signal processing pipeline using the available\n",
    "functions in Medusa: (1) preprocessing, (2) feature extraction, (3) feature\n",
    "selection, (4) feature classification, and (5) command decoding.\n",
    "\n",
    "Concretely, we will use a deep convolutional neural network specifically\n",
    "designed for BCI applications: EEG-Inception. Check this reference to understand\n",
    "all the details of this model [1]. In order to continue with the tutorial,\n",
    "we recommend a  python environment with the GPU version of tensorflow (v 2.0+)\n",
    "to reduce the  training time. If you don't have access to this environment,\n",
    "don't worry, it will take only a few minutes.\n",
    "\n",
    "Run the following cell to create and fit the model for the command decoding\n",
    "task. In other words, the model that guess the intentions of the user directly\n",
    "from the EEG. This model is ready to use in compatible online applications,\n",
    "such as the RCP app included in Medusa platform."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Programs\\Anaconda\\envs\\medusa-dev\\lib\\site-packages\\medusa\\bci\\erp_spellers.py:1423: UserWarning: Non-control trials detected. Only control trials will be used to fit the ERP speller model.\n",
      "  warnings.warn('Non-control trials detected. Only control '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "7/7 [==============================] - 17s 520ms/step - loss: 0.8467 - accuracy: 0.5350 - val_loss: 0.5778 - val_accuracy: 0.7361\n",
      "Epoch 2/500\n",
      "7/7 [==============================] - 0s 55ms/step - loss: 0.6535 - accuracy: 0.6500 - val_loss: 0.4908 - val_accuracy: 0.7905\n",
      "Epoch 3/500\n",
      "7/7 [==============================] - 0s 55ms/step - loss: 0.5542 - accuracy: 0.7246 - val_loss: 0.4657 - val_accuracy: 0.8102\n",
      "Epoch 4/500\n",
      "7/7 [==============================] - 0s 55ms/step - loss: 0.4962 - accuracy: 0.7781 - val_loss: 0.4503 - val_accuracy: 0.8032\n",
      "Epoch 5/500\n",
      "7/7 [==============================] - 0s 55ms/step - loss: 0.4631 - accuracy: 0.8082 - val_loss: 0.4433 - val_accuracy: 0.8056\n",
      "Epoch 6/500\n",
      "7/7 [==============================] - 0s 55ms/step - loss: 0.4540 - accuracy: 0.8157 - val_loss: 0.4252 - val_accuracy: 0.8206\n",
      "Epoch 7/500\n",
      "7/7 [==============================] - 0s 55ms/step - loss: 0.4332 - accuracy: 0.8263 - val_loss: 0.4119 - val_accuracy: 0.8356\n",
      "Epoch 8/500\n",
      "7/7 [==============================] - 0s 55ms/step - loss: 0.4538 - accuracy: 0.8091 - val_loss: 0.4001 - val_accuracy: 0.8438\n",
      "Epoch 9/500\n",
      "7/7 [==============================] - 0s 55ms/step - loss: 0.4278 - accuracy: 0.8250 - val_loss: 0.3906 - val_accuracy: 0.8519\n",
      "Epoch 10/500\n",
      "7/7 [==============================] - 0s 55ms/step - loss: 0.4354 - accuracy: 0.8202 - val_loss: 0.3838 - val_accuracy: 0.8553\n",
      "Epoch 11/500\n",
      "7/7 [==============================] - 0s 55ms/step - loss: 0.4167 - accuracy: 0.8277 - val_loss: 0.3778 - val_accuracy: 0.8530\n",
      "Epoch 12/500\n",
      "7/7 [==============================] - 0s 55ms/step - loss: 0.4211 - accuracy: 0.8254 - val_loss: 0.3709 - val_accuracy: 0.8565\n",
      "Epoch 13/500\n",
      "7/7 [==============================] - 0s 55ms/step - loss: 0.4003 - accuracy: 0.8361 - val_loss: 0.3654 - val_accuracy: 0.8530\n",
      "Epoch 14/500\n",
      "7/7 [==============================] - 0s 55ms/step - loss: 0.3869 - accuracy: 0.8402 - val_loss: 0.3617 - val_accuracy: 0.8553\n",
      "Epoch 15/500\n",
      "7/7 [==============================] - 0s 55ms/step - loss: 0.4049 - accuracy: 0.8258 - val_loss: 0.3587 - val_accuracy: 0.8553\n",
      "Epoch 16/500\n",
      "7/7 [==============================] - 0s 55ms/step - loss: 0.4023 - accuracy: 0.8351 - val_loss: 0.3571 - val_accuracy: 0.8588\n",
      "Epoch 17/500\n",
      "7/7 [==============================] - 0s 56ms/step - loss: 0.3835 - accuracy: 0.8390 - val_loss: 0.3521 - val_accuracy: 0.8553\n",
      "Epoch 18/500\n",
      "7/7 [==============================] - 0s 57ms/step - loss: 0.3689 - accuracy: 0.8480 - val_loss: 0.3507 - val_accuracy: 0.8600\n",
      "Epoch 19/500\n",
      "7/7 [==============================] - 0s 56ms/step - loss: 0.3901 - accuracy: 0.8368 - val_loss: 0.3484 - val_accuracy: 0.8657\n",
      "Epoch 20/500\n",
      "7/7 [==============================] - 0s 55ms/step - loss: 0.3873 - accuracy: 0.8358 - val_loss: 0.3475 - val_accuracy: 0.8657\n",
      "Epoch 21/500\n",
      "7/7 [==============================] - 0s 55ms/step - loss: 0.3798 - accuracy: 0.8420 - val_loss: 0.3466 - val_accuracy: 0.8600\n",
      "Epoch 22/500\n",
      "7/7 [==============================] - 0s 55ms/step - loss: 0.3850 - accuracy: 0.8358 - val_loss: 0.3451 - val_accuracy: 0.8588\n",
      "Epoch 23/500\n",
      "7/7 [==============================] - 0s 55ms/step - loss: 0.3807 - accuracy: 0.8405 - val_loss: 0.3437 - val_accuracy: 0.8646\n",
      "Epoch 24/500\n",
      "7/7 [==============================] - 0s 55ms/step - loss: 0.3727 - accuracy: 0.8451 - val_loss: 0.3438 - val_accuracy: 0.8611\n",
      "Epoch 25/500\n",
      "7/7 [==============================] - 0s 56ms/step - loss: 0.3772 - accuracy: 0.8456 - val_loss: 0.3429 - val_accuracy: 0.8634\n",
      "Epoch 26/500\n",
      "7/7 [==============================] - 0s 57ms/step - loss: 0.3806 - accuracy: 0.8394 - val_loss: 0.3408 - val_accuracy: 0.8704\n",
      "Epoch 27/500\n",
      "7/7 [==============================] - 0s 55ms/step - loss: 0.3738 - accuracy: 0.8435 - val_loss: 0.3382 - val_accuracy: 0.8681\n",
      "Epoch 28/500\n",
      "7/7 [==============================] - 0s 55ms/step - loss: 0.3706 - accuracy: 0.8412 - val_loss: 0.3380 - val_accuracy: 0.8657\n",
      "Epoch 29/500\n",
      "7/7 [==============================] - 0s 55ms/step - loss: 0.3670 - accuracy: 0.8511 - val_loss: 0.3385 - val_accuracy: 0.8727\n",
      "Epoch 30/500\n",
      "7/7 [==============================] - 0s 56ms/step - loss: 0.3681 - accuracy: 0.8375 - val_loss: 0.3367 - val_accuracy: 0.8727\n",
      "Epoch 31/500\n",
      "7/7 [==============================] - 0s 55ms/step - loss: 0.3755 - accuracy: 0.8346 - val_loss: 0.3357 - val_accuracy: 0.8669\n",
      "Epoch 32/500\n",
      "7/7 [==============================] - 0s 55ms/step - loss: 0.3631 - accuracy: 0.8453 - val_loss: 0.3355 - val_accuracy: 0.8704\n",
      "Epoch 33/500\n",
      "7/7 [==============================] - 0s 56ms/step - loss: 0.3471 - accuracy: 0.8526 - val_loss: 0.3377 - val_accuracy: 0.8727\n",
      "Epoch 34/500\n",
      "7/7 [==============================] - 0s 55ms/step - loss: 0.3567 - accuracy: 0.8460 - val_loss: 0.3372 - val_accuracy: 0.8681\n",
      "Epoch 35/500\n",
      "7/7 [==============================] - 0s 59ms/step - loss: 0.3442 - accuracy: 0.8584 - val_loss: 0.3346 - val_accuracy: 0.8646\n",
      "Epoch 36/500\n",
      "7/7 [==============================] - 0s 55ms/step - loss: 0.3630 - accuracy: 0.8439 - val_loss: 0.3318 - val_accuracy: 0.8681\n",
      "Epoch 37/500\n",
      "7/7 [==============================] - 0s 55ms/step - loss: 0.3625 - accuracy: 0.8488 - val_loss: 0.3298 - val_accuracy: 0.8669\n",
      "Epoch 38/500\n",
      "7/7 [==============================] - 0s 55ms/step - loss: 0.3545 - accuracy: 0.8454 - val_loss: 0.3317 - val_accuracy: 0.8681\n",
      "Epoch 39/500\n",
      "7/7 [==============================] - 0s 55ms/step - loss: 0.3506 - accuracy: 0.8497 - val_loss: 0.3335 - val_accuracy: 0.8657\n",
      "Epoch 40/500\n",
      "7/7 [==============================] - 0s 55ms/step - loss: 0.3519 - accuracy: 0.8494 - val_loss: 0.3310 - val_accuracy: 0.8669\n",
      "Epoch 41/500\n",
      "7/7 [==============================] - 0s 55ms/step - loss: 0.3554 - accuracy: 0.8473 - val_loss: 0.3331 - val_accuracy: 0.8715\n",
      "Epoch 42/500\n",
      "7/7 [==============================] - 0s 55ms/step - loss: 0.3571 - accuracy: 0.8502 - val_loss: 0.3330 - val_accuracy: 0.8646\n",
      "Epoch 43/500\n",
      "7/7 [==============================] - 0s 55ms/step - loss: 0.3475 - accuracy: 0.8572 - val_loss: 0.3325 - val_accuracy: 0.8634\n",
      "Epoch 44/500\n",
      "7/7 [==============================] - 0s 55ms/step - loss: 0.3481 - accuracy: 0.8479 - val_loss: 0.3313 - val_accuracy: 0.8681\n",
      "Epoch 45/500\n",
      "7/7 [==============================] - 0s 55ms/step - loss: 0.3558 - accuracy: 0.8508 - val_loss: 0.3310 - val_accuracy: 0.8681\n",
      "Epoch 46/500\n",
      "7/7 [==============================] - 0s 55ms/step - loss: 0.3570 - accuracy: 0.8471 - val_loss: 0.3296 - val_accuracy: 0.8669\n",
      "Epoch 47/500\n",
      "7/7 [==============================] - 0s 55ms/step - loss: 0.3486 - accuracy: 0.8512 - val_loss: 0.3302 - val_accuracy: 0.8681\n",
      "Epoch 48/500\n",
      "7/7 [==============================] - 0s 55ms/step - loss: 0.3595 - accuracy: 0.8443 - val_loss: 0.3310 - val_accuracy: 0.8657\n",
      "Epoch 49/500\n",
      "7/7 [==============================] - 0s 55ms/step - loss: 0.3409 - accuracy: 0.8520 - val_loss: 0.3306 - val_accuracy: 0.8646\n",
      "Epoch 50/500\n",
      "7/7 [==============================] - 0s 55ms/step - loss: 0.3479 - accuracy: 0.8504 - val_loss: 0.3292 - val_accuracy: 0.8634\n",
      "Epoch 51/500\n",
      "7/7 [==============================] - 0s 55ms/step - loss: 0.3470 - accuracy: 0.8541 - val_loss: 0.3292 - val_accuracy: 0.8646\n",
      "Epoch 52/500\n",
      "7/7 [==============================] - 0s 58ms/step - loss: 0.3548 - accuracy: 0.8505 - val_loss: 0.3288 - val_accuracy: 0.8634\n",
      "Epoch 53/500\n",
      "7/7 [==============================] - 0s 56ms/step - loss: 0.3396 - accuracy: 0.8534 - val_loss: 0.3285 - val_accuracy: 0.8646\n",
      "Epoch 54/500\n",
      "7/7 [==============================] - 0s 56ms/step - loss: 0.3368 - accuracy: 0.8501 - val_loss: 0.3281 - val_accuracy: 0.8611\n",
      "Epoch 55/500\n",
      "7/7 [==============================] - 0s 56ms/step - loss: 0.3389 - accuracy: 0.8564 - val_loss: 0.3278 - val_accuracy: 0.8646\n",
      "Epoch 56/500\n",
      "7/7 [==============================] - 0s 55ms/step - loss: 0.3507 - accuracy: 0.8483 - val_loss: 0.3291 - val_accuracy: 0.8634\n",
      "Epoch 57/500\n",
      "7/7 [==============================] - 0s 55ms/step - loss: 0.3366 - accuracy: 0.8600 - val_loss: 0.3269 - val_accuracy: 0.8692\n",
      "Epoch 58/500\n",
      "7/7 [==============================] - 0s 55ms/step - loss: 0.3461 - accuracy: 0.8501 - val_loss: 0.3281 - val_accuracy: 0.8669\n",
      "Epoch 59/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 55ms/step - loss: 0.3503 - accuracy: 0.8494 - val_loss: 0.3289 - val_accuracy: 0.8646\n",
      "Epoch 60/500\n",
      "7/7 [==============================] - 0s 55ms/step - loss: 0.3582 - accuracy: 0.8503 - val_loss: 0.3268 - val_accuracy: 0.8634\n",
      "Epoch 61/500\n",
      "7/7 [==============================] - 0s 55ms/step - loss: 0.3410 - accuracy: 0.8496 - val_loss: 0.3249 - val_accuracy: 0.8657\n",
      "Epoch 62/500\n",
      "7/7 [==============================] - 0s 55ms/step - loss: 0.3391 - accuracy: 0.8559 - val_loss: 0.3283 - val_accuracy: 0.8600\n",
      "Epoch 63/500\n",
      "7/7 [==============================] - 0s 55ms/step - loss: 0.3510 - accuracy: 0.8491 - val_loss: 0.3291 - val_accuracy: 0.8611\n",
      "Epoch 64/500\n",
      "7/7 [==============================] - 0s 55ms/step - loss: 0.3305 - accuracy: 0.8562 - val_loss: 0.3264 - val_accuracy: 0.8634\n",
      "Epoch 65/500\n",
      "7/7 [==============================] - 0s 55ms/step - loss: 0.3387 - accuracy: 0.8586 - val_loss: 0.3225 - val_accuracy: 0.8681\n",
      "Epoch 66/500\n",
      "7/7 [==============================] - 0s 55ms/step - loss: 0.3390 - accuracy: 0.8517 - val_loss: 0.3243 - val_accuracy: 0.8681\n",
      "Epoch 67/500\n",
      "7/7 [==============================] - 0s 58ms/step - loss: 0.3359 - accuracy: 0.8513 - val_loss: 0.3253 - val_accuracy: 0.8611\n",
      "Epoch 68/500\n",
      "7/7 [==============================] - 0s 55ms/step - loss: 0.3343 - accuracy: 0.8582 - val_loss: 0.3256 - val_accuracy: 0.8611\n",
      "Epoch 69/500\n",
      "7/7 [==============================] - 0s 56ms/step - loss: 0.3415 - accuracy: 0.8605 - val_loss: 0.3240 - val_accuracy: 0.8657\n",
      "Epoch 70/500\n",
      "7/7 [==============================] - 0s 55ms/step - loss: 0.3390 - accuracy: 0.8608 - val_loss: 0.3238 - val_accuracy: 0.8692\n",
      "Epoch 71/500\n",
      "7/7 [==============================] - 0s 55ms/step - loss: 0.3523 - accuracy: 0.8545 - val_loss: 0.3241 - val_accuracy: 0.8669\n",
      "Epoch 72/500\n",
      "7/7 [==============================] - 0s 57ms/step - loss: 0.3387 - accuracy: 0.8583 - val_loss: 0.3251 - val_accuracy: 0.8669\n",
      "Epoch 73/500\n",
      "7/7 [==============================] - 0s 55ms/step - loss: 0.3350 - accuracy: 0.8581 - val_loss: 0.3240 - val_accuracy: 0.8623\n",
      "Epoch 74/500\n",
      "7/7 [==============================] - 0s 55ms/step - loss: 0.3350 - accuracy: 0.8624 - val_loss: 0.3246 - val_accuracy: 0.8704\n",
      "Epoch 75/500\n",
      "7/7 [==============================] - 0s 55ms/step - loss: 0.3483 - accuracy: 0.8519 - val_loss: 0.3257 - val_accuracy: 0.8646\n",
      "Epoch 76/500\n",
      "7/7 [==============================] - 0s 55ms/step - loss: 0.3296 - accuracy: 0.8580 - val_loss: 0.3263 - val_accuracy: 0.8634\n",
      "Epoch 77/500\n",
      "7/7 [==============================] - 0s 55ms/step - loss: 0.3308 - accuracy: 0.8604 - val_loss: 0.3236 - val_accuracy: 0.8681\n",
      "Epoch 78/500\n",
      "7/7 [==============================] - 0s 55ms/step - loss: 0.3345 - accuracy: 0.8555 - val_loss: 0.3244 - val_accuracy: 0.8669\n",
      "Epoch 79/500\n",
      "7/7 [==============================] - 0s 56ms/step - loss: 0.3202 - accuracy: 0.8694 - val_loss: 0.3222 - val_accuracy: 0.8715\n",
      "Epoch 80/500\n",
      "7/7 [==============================] - 0s 58ms/step - loss: 0.3356 - accuracy: 0.8636 - val_loss: 0.3226 - val_accuracy: 0.8704\n",
      "Epoch 81/500\n",
      "7/7 [==============================] - 0s 56ms/step - loss: 0.3403 - accuracy: 0.8554 - val_loss: 0.3253 - val_accuracy: 0.8715\n",
      "Epoch 82/500\n",
      "7/7 [==============================] - 0s 56ms/step - loss: 0.3308 - accuracy: 0.8599 - val_loss: 0.3267 - val_accuracy: 0.8669\n",
      "Epoch 83/500\n",
      "7/7 [==============================] - 0s 55ms/step - loss: 0.3224 - accuracy: 0.8621 - val_loss: 0.3221 - val_accuracy: 0.8704\n",
      "Epoch 84/500\n",
      "7/7 [==============================] - 0s 55ms/step - loss: 0.3337 - accuracy: 0.8527 - val_loss: 0.3223 - val_accuracy: 0.8727\n",
      "Epoch 85/500\n",
      "7/7 [==============================] - 0s 55ms/step - loss: 0.3211 - accuracy: 0.8635 - val_loss: 0.3272 - val_accuracy: 0.8692\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00085: early stopping\n",
      "\n",
      "Train accuracy per number of sequences of stimulation:\n",
      "\n",
      "                        1      2    3      4      5     6      7      8      9     10    11    12    13    14    15\n",
      "--------------------  ---  -----  ---  -----  -----  ----  -----  -----  -----  -----  ----  ----  ----  ----  ----\n",
      "Command decoding acc   25  33.33   50  70.83  83.33  87.5  91.67  91.67  91.67  95.83   100   100   100   100   100\n"
     ]
    }
   ],
   "source": [
    "# Instantiate CMDModelEEGInception\n",
    "cmd_model = erp_spellers.CMDModelEEGInception(n_cha=4)\n",
    "# Fit model\n",
    "cmd_fit_results = cmd_model.fit_dataset(dataset,\n",
    "                                        validation_split=0.2,\n",
    "                                        batch_size=512)\n",
    "\n",
    "# Print fit results\n",
    "print_acc_per_seq(cmd_fit_results['spell_acc_per_seq'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Control state detection model\n",
    "\n",
    "There is one limitation that the previous model cannot solve. ERP-based spellers\n",
    "are, inherently, synchronous systems. They always make a selection even when the\n",
    "user is not attending to the stimuli. Nevertheless, this behaviour is not\n",
    "suitable for real applications, where an asynchronous operation is required.\n",
    "Do you imagine a web-browser based on an ERP-based speller in which you\n",
    "cannot read the web page you searched because the system keeps making\n",
    "selections?. Despite the futility of a synchronous system, most approaches to\n",
    "date do not address this issue. In order to achieve an asynchronous approach,\n",
    "we will need 2 types of models:\n",
    "\n",
    "    - Command decoding models (CMD): these models are in charge of the\n",
    "      command decoding task by detecting the ERPs within the EEG epochs to\n",
    "      decode the user's instentions. The previous model solves this task.\n",
    "    - Control state detection models (CSD): these models are in charge of the\n",
    "      control state detection task, which detects if users are attending to the\n",
    "      stimuli or if they are engaged in other activities.\n",
    "\n",
    "It is important to understand that both models are necessary to build the\n",
    "complete signal processing pipeline of an ERP-based speller. Scientists have\n",
    "been traditionally focused in the command decoding task. Nevertheless,\n",
    "ERP-based spellers are useless if they do not detect if the user is controlling\n",
    "the BCI application or is doing something else! Keep that in mind in your\n",
    "designs for real-life applications. In last years, we have worked hard to solve\n",
    "this issue, achieving quite a success. To know more about this problem and\n",
    "our work in the field, check references [2], [3] and [4].\n",
    "\n",
    "In this tutorial we will use the class medusa.erp_spellers.CSDModelEEGInception\n",
    "to achieve an asynchronous ERP-based speller."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%% cd\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "14/14 [==============================] - 3s 155ms/step - loss: 0.8515 - accuracy: 0.4952 - val_loss: 0.7628 - val_accuracy: 0.5318\n",
      "Epoch 2/500\n",
      "14/14 [==============================] - 1s 53ms/step - loss: 0.7305 - accuracy: 0.5485 - val_loss: 0.7743 - val_accuracy: 0.5365\n",
      "Epoch 3/500\n",
      "14/14 [==============================] - 1s 53ms/step - loss: 0.6807 - accuracy: 0.5815 - val_loss: 0.7671 - val_accuracy: 0.5486\n",
      "Epoch 4/500\n",
      "14/14 [==============================] - 1s 53ms/step - loss: 0.6410 - accuracy: 0.6209 - val_loss: 0.6850 - val_accuracy: 0.6042\n",
      "Epoch 5/500\n",
      "14/14 [==============================] - 1s 53ms/step - loss: 0.5983 - accuracy: 0.6777 - val_loss: 0.6492 - val_accuracy: 0.6418\n",
      "Epoch 6/500\n",
      "14/14 [==============================] - 1s 53ms/step - loss: 0.5717 - accuracy: 0.7062 - val_loss: 0.7105 - val_accuracy: 0.6082\n",
      "Epoch 7/500\n",
      "14/14 [==============================] - 1s 52ms/step - loss: 0.5406 - accuracy: 0.7339 - val_loss: 0.6903 - val_accuracy: 0.6157\n",
      "Epoch 8/500\n",
      "14/14 [==============================] - 1s 53ms/step - loss: 0.5250 - accuracy: 0.7421 - val_loss: 0.8189 - val_accuracy: 0.5764\n",
      "Epoch 9/500\n",
      "14/14 [==============================] - 1s 53ms/step - loss: 0.5117 - accuracy: 0.7511 - val_loss: 0.8690 - val_accuracy: 0.5683\n",
      "Epoch 10/500\n",
      "14/14 [==============================] - 1s 52ms/step - loss: 0.5027 - accuracy: 0.7502 - val_loss: 0.8984 - val_accuracy: 0.5584\n",
      "Epoch 11/500\n",
      "14/14 [==============================] - 1s 52ms/step - loss: 0.4921 - accuracy: 0.7720 - val_loss: 0.9472 - val_accuracy: 0.5608\n",
      "Epoch 12/500\n",
      "14/14 [==============================] - 1s 53ms/step - loss: 0.4786 - accuracy: 0.7776 - val_loss: 0.9140 - val_accuracy: 0.5654\n",
      "Epoch 13/500\n",
      "14/14 [==============================] - 1s 53ms/step - loss: 0.4722 - accuracy: 0.7747 - val_loss: 1.0019 - val_accuracy: 0.5469\n",
      "Epoch 14/500\n",
      "14/14 [==============================] - 1s 53ms/step - loss: 0.4648 - accuracy: 0.7787 - val_loss: 1.0307 - val_accuracy: 0.5451\n",
      "Epoch 15/500\n",
      "14/14 [==============================] - 1s 53ms/step - loss: 0.4647 - accuracy: 0.7791 - val_loss: 0.9900 - val_accuracy: 0.5498\n",
      "Epoch 16/500\n",
      "14/14 [==============================] - 1s 53ms/step - loss: 0.4554 - accuracy: 0.7807 - val_loss: 1.0278 - val_accuracy: 0.5503\n",
      "Epoch 17/500\n",
      "14/14 [==============================] - 1s 53ms/step - loss: 0.4448 - accuracy: 0.7917 - val_loss: 1.0240 - val_accuracy: 0.5492\n",
      "Epoch 18/500\n",
      "13/14 [==========================>...] - ETA: 0s - loss: 0.4609 - accuracy: 0.7852"
     ]
    }
   ],
   "source": [
    "# Instantiate CSDModelEEGInception\n",
    "csd_model = erp_spellers.CSDModelEEGInception(n_cha=4)\n",
    "# Train model\n",
    "csd_fit_results = csd_model.fit_dataset(dataset,\n",
    "                                        validation_split=0.2,\n",
    "                                        batch_size=512)\n",
    "\n",
    "# Print fit results\n",
    "print_acc_per_seq(csd_fit_results['control_state_acc_per_seq'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model persistence\n",
    "\n",
    "Now you can save your models to use them later. An important feature is that\n",
    "all models that inherit from erp_spellers.ERPSpellerModel can be loaded in\n",
    "the compatible apps of Medusa platform, so you can try them in online\n",
    "experiments!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%% cd\n"
    }
   },
   "outputs": [],
   "source": [
    "# Save the models\n",
    "cmd_model.save('cmd_model.pkl')\n",
    "csd_model.save('csd_model.pkl')\n",
    "\n",
    "print('OK!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Load models\n",
    "\n",
    "Congratulations! The files cmd_model.pkl and csd_model.pkl that have been\n",
    "created in your working directory contain a standalone version of the models in\n",
    "their current state ready to use for offline processing or online applications\n",
    "on Medusa platform. To load the models, use the following code:\n",
    "\n",
    "    >>> from medusa.bci import erp_spellers\n",
    "    >>> cmd_model = erp_spellers.ERPSpellerModel.load('cmd_model.pkl')\n",
    "    >>> csd_model = erp_spellers.ERPSpellerModel.load('csd_model.pkl')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Conclusion\n",
    "\n",
    "That's all for now! Now you have a comprehensive picture of the functions and\n",
    "classes included in the module. As you can see, you can build the full signal\n",
    "processing pipeline of an ERP-based speller in few code lines using Medusa!\n",
    "\n",
    "See you in the next tutorial."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## References\n",
    "\n",
    "Check the following references for extended information about some of the\n",
    "aspects of this tutorial:\n",
    "\n",
    "1. Santamaría-Vázquez, E., Martínez-Cagigal, V., Vaquerizo-Villar, F., &\n",
    "Hornero, R. (2020). EEG-Inception: A Novel Deep Convolutional Neural Network for\n",
    "Assistive ERP-based Brain-Computer Interfaces. IEEE Transactions on Neural\n",
    "Systems and Rehabilitation Engineering.\n",
    "2. Santamaría-Vázquez, E., Martínez-Cagigal, V., Gomez-Pilar, J., & Hornero,\n",
    "R. (2019). Asynchronous Control of ERP-Based BCI Spellers Using Steady-State\n",
    "Visual Evoked Potentials Elicited by Peripheral Stimuli. IEEE Transactions on\n",
    "Neural Systems and Rehabilitation Engineering, 27(9), 1883-1892.\n",
    "3. Martínez-Cagigal, V., Santamaría-Vázquez, E., & Hornero, R. (2019). \n",
    "Asynchronous control of P300-based brain–computer interfaces using sample \n",
    "entropy. Entropy, 21(3), 230.\n",
    "4. XXX\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}