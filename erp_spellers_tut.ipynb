{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Welcome to the ERP-based speller analysis tutorial!\n",
    "\n",
    "Event-related potentials (ERPs) have been used to implement non-invasive\n",
    "brain-computer interface (BCI) literature for their ability to  enable\n",
    "reliable, high-speed control. This control signal arise from the\n",
    "brain's exogenous responses to single stimulus.\n",
    "\n",
    "This module contains high level classes and functions specifically designed\n",
    "for ERP-based spellers. This notebook will cover the main features, functions\n",
    "and classes of the module through illustrative examples which will show you\n",
    "the power of the included tools.\n",
    "\n",
    "In this notebook, you will learn how to:\n",
    "- Load electroencephalographic (EEG) signals from an experiment performed with the RCP Recorder app\n",
    "- Plot the ERPs from pre-recorded data\n",
    "- Calibrate the system using the reference processing pipeline.\n",
    "- Decode the selected commands during a free-spelling phase and evaluate performance metrics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Our ERP-based Speller\n",
    "\n",
    "### Experiment briefing\n",
    "In this tutorial, we will work with pre-recorded data from a user participating in an ERP-based Speller experiment using the __[`RCP Speller`](https://www.medusabci.com/market/rcp_speller/)__ app from __[MEDUSAÂ©](https://www.medusabci.com)__.\n",
    "\n",
    "The objective of the experiment was to control a RCP speller composed of 36 alphanumeric commands (letters A to Z, numbers 0 to 9). These commands were encoded using classical row-column paradigm.\n",
    "\n",
    "During the calibration phase, the user focused on predefined commands for 3 runs, each consisting of 6 trials. Each trial included 15 stimulation sequences. In the online phase, the user engaged in free-spelling for 2 runs of 6 trials each (again with 15 stimulation sequences). The user was given a predefined target to assess the performance of the model later on. The EEG data were recorded from 16 active channels positioned at FZ, CZ, PZ, P3, P4, PO7, PO8, OZ, POZ, CPZ, F3, C3, PO3, F4, C4, PO4, with a sampling rate of 256 Hz.\n",
    "\n",
    "\n",
    "### Load calibration and test data\n",
    "First, if you are using Google Colab, execute the following cell to install `medusa-kernel` and clone the GitHub repository to obtain the EEG recordings.\n",
    "\n",
    "<div class=\"alert alert-block alert-danger\">\n",
    "Important: execute the following cell **only** if you're using Google Collab!\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "!pip install medusa-kernel\n",
    "!git clone https://github.com/medusabci/medusa-tutorials.git"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialization and recording exploration\n",
    "\n",
    "Let's import the necessary modules for this notebook and define some useful functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%% cd\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 21.3.1; however, version 24.0 is available.\n",
      "You should consider upgrading via the 'D:\\MEDUSA\\medusa-tutorials\\venv\\Scripts\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: medusa-kernel in c:\\users\\diego\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (1.3.0)\n",
      "Requirement already satisfied: dill in c:\\users\\diego\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from medusa-kernel) (0.3.6)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\diego\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from medusa-kernel) (1.2.0)\n",
      "Requirement already satisfied: statsmodels in c:\\users\\diego\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from medusa-kernel) (0.13.5)\n",
      "Requirement already satisfied: bson in c:\\users\\diego\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from medusa-kernel) (0.5.10)\n",
      "Requirement already satisfied: scipy in c:\\users\\diego\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from medusa-kernel) (1.8.1)\n",
      "Requirement already satisfied: h5py in c:\\users\\diego\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from medusa-kernel) (3.7.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\diego\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from medusa-kernel) (1.23.1)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\diego\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from medusa-kernel) (3.6.2)\n",
      "Requirement already satisfied: tqdm in c:\\users\\diego\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from medusa-kernel) (4.64.1)\n",
      "Requirement already satisfied: python-dateutil>=2.4.0 in c:\\users\\diego\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from bson->medusa-kernel) (2.8.2)\n",
      "Requirement already satisfied: six>=1.9.0 in c:\\users\\diego\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from bson->medusa-kernel) (1.16.0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\diego\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib->medusa-kernel) (22.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\diego\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib->medusa-kernel) (4.38.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\diego\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib->medusa-kernel) (0.11.0)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\diego\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib->medusa-kernel) (9.3.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\diego\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib->medusa-kernel) (1.0.6)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\diego\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib->medusa-kernel) (1.4.4)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in c:\\users\\diego\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib->medusa-kernel) (3.0.9)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\diego\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from scikit-learn->medusa-kernel) (3.1.0)\n",
      "Requirement already satisfied: joblib>=1.1.1 in c:\\users\\diego\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from scikit-learn->medusa-kernel) (1.2.0)\n",
      "Requirement already satisfied: patsy>=0.5.2 in c:\\users\\diego\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from statsmodels->medusa-kernel) (0.5.3)\n",
      "Requirement already satisfied: pandas>=0.25 in c:\\users\\diego\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from statsmodels->medusa-kernel) (1.5.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\diego\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tqdm->medusa-kernel) (0.4.6)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\diego\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pandas>=0.25->statsmodels->medusa-kernel) (2022.6)\n",
      "OK!\n"
     ]
    }
   ],
   "source": [
    "# External imports\n",
    "import glob\n",
    "from tabulate import tabulate\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "# Medusa imports\n",
    "from medusa import components\n",
    "from medusa.bci import erp_spellers\n",
    "from medusa.plots import erp_plots\n",
    "print('> Import successful!')\n",
    "\n",
    "def print_acc_per_seq(acc_per_seq, title):\n",
    "    table_cmd_acc_per_seq = ['Command decoding acc']\n",
    "    cmd_acc_per_seq = np.char.mod('%.2f', acc_per_seq*100).astype(str).tolist()\n",
    "    table_cmd_acc_per_seq += cmd_acc_per_seq\n",
    "    headers = [''] + list(range(1, 16))\n",
    "    print('\\n%s\\n' % title)\n",
    "    print(tabulate([table_cmd_acc_per_seq], headers=headers))\n",
    "print('> Auxiliary functions defined!')\n",
    "\n",
    "# Define the data folder\n",
    "folder = 'medusa-tutorials/rcp_speller/'"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Next, we'll load the first recording to explore some variables."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%% cd\n"
    }
   },
   "outputs": [],
   "source": [
    "# Find subject data\n",
    "print('> Loading subject data...')\n",
    "file_pattern = '*.rcp.bson'\n",
    "files = glob.glob('%s/%s' % (folder, file_pattern))\n",
    "print('   - Detected %i recordings' % len(files))\n",
    "\n",
    "# Load first recording and explore the variables\n",
    "print('> Exploring the first recording...')\n",
    "rec = components.Recording.load(files[0])\n",
    "print('   - Number of trials: %.i' % np.unique(\n",
    "    rec.erpspellerdata.trial_idx).shape[0])\n",
    "print('   - Sampling rate: %.2f Hz' % rec.eeg.fs)\n",
    "print('   - EEG registered at %i positions: %s' % (\n",
    "    len(rec.eeg.channel_set.l_cha),\n",
    "    ', '.join(rec.eeg.channel_set.l_cha)))"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Plot ERPs\n",
    "\n",
    "Now, we'll load all the recoordings and compile them into a dataset. This\n",
    "ensures consistency across the signals, maintaining uniform experimental\n",
    "conditions, e.g. the sampling rate or channel set.\n",
    "\n",
    "Then, this dataset will be used to plot the ERPs."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Create subject dataset\n",
    "print('> Creating subject dataset...')\n",
    "subj_dataset = erp_spellers.ERPSpellerDataset(\n",
    "    channel_set=rec.eeg.channel_set,\n",
    "    fs=256,\n",
    "    biosignal_att_key='eeg',\n",
    "    experiment_att_key='erpspellerdata',\n",
    "    experiment_mode='train')\n",
    "subj_dataset.add_recordings(files)\n",
    "\n",
    "# Plot ERPs\n",
    "print('> Plot ERPs in all channels')\n",
    "# Signal processing\n",
    "prep_method = erp_spellers.StandardPreprocessing(cutoff=(1, 30))\n",
    "feat_ext_method = erp_spellers.StandardFeatureExtraction(\n",
    "    w_epoch_t=(0, 800),\n",
    "    target_fs=100,\n",
    "    concatenate_channels=False)\n",
    "subj_dataset = prep_method.fit_transform_dataset(subj_dataset)\n",
    "x, x_info = feat_ext_method.transform_dataset(subj_dataset)\n",
    "trials_erp_epochs = x[x_info['erp_labels'] == 1]\n",
    "trials_noerp_epochs = x[x_info['erp_labels'] == 0]\n",
    "# Show figure with ERPs\n",
    "with plt.style.context('seaborn'):\n",
    "    fig, axs = plt.subplots(3, 4, figsize=(16, 6))\n",
    "    # Plot ERPs\n",
    "    for i, ax in enumerate(axs.flat):\n",
    "        ax.set_title(f'Channel {subj_dataset.channel_set.l_cha[i]}')\n",
    "        plot_data = erp_plots.plot_erp(erp_epochs=trials_erp_epochs,\n",
    "                                       noerp_epochs=trials_noerp_epochs,\n",
    "                                       channel=i,\n",
    "                                       window=[0, 800],\n",
    "                                       error_measure=\"C65\",\n",
    "                                       plot=False)\n",
    "        t = np.linspace(0, 800, plot_data[\"trials_erp_mean\"].shape[0])\n",
    "        ax.plot(t, plot_data[\"trials_erp_mean\"])\n",
    "        ax.fill_between(t, plot_data[\"trials_erp_dev\"][0],\n",
    "                        plot_data[\"trials_erp_dev\"][1],\n",
    "                        alpha=0.3)\n",
    "        ax.plot(t, plot_data[\"trials_noerp_mean\"])\n",
    "        ax.fill_between(t, plot_data[\"trials_noerp_dev\"][0],\n",
    "                        plot_data[\"trials_noerp_dev\"][1],\n",
    "                        alpha=0.3)\n",
    "\n",
    "        if i == subj_dataset.channel_set.n_cha:\n",
    "            break\n",
    "\n",
    "    # Show the figure\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% cd\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calibration stage\n",
    "The next step is to train a model using the calibration recordings. In this\n",
    "process, signal processing follows the reference processing based on regularized\n",
    "linear discriminant analysis (rLDA)\n",
    "\n",
    "We'll only use the training recordings. Then we create and fit the model.\n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "For more detailed information on this reference processing approach, please\n",
    "refer to references [1, 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%% cd\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK!\n"
     ]
    }
   ],
   "source": [
    "# Create calibration dataset\n",
    "print('> Creating calibration dataset...')\n",
    "file_pattern = '*TRAIN*.rcp.bson'\n",
    "training_files = glob.glob('%s/%s' % (folder, file_pattern))\n",
    "print('   - Detected %i training recordings' % len(training_files))\n",
    "train_dataset = erp_spellers.ERPSpellerDataset(\n",
    "    channel_set=rec.eeg.channel_set,\n",
    "    fs=256,\n",
    "    biosignal_att_key='eeg',\n",
    "    experiment_att_key='erpspellerdata',\n",
    "    experiment_mode='train')\n",
    "train_dataset.add_recordings(training_files)\n",
    "\n",
    "# Create model\n",
    "print('> Create rLDA model')\n",
    "cmd_model = erp_spellers.CMDModelRLDA()\n",
    "cmd_model.configure()\n",
    "cmd_model.build()\n",
    "\n",
    "# Fit model\n",
    "print('> Fit model with the training dataset')\n",
    "cmd_fit_results = cmd_model.fit_dataset(train_dataset,\n",
    "                                        validation_split=0.2,\n",
    "                                        batch_size=512)\n",
    "\n",
    "# Print fit results\n",
    "print_acc_per_seq(cmd_fit_results['spell_acc_per_seq'],\n",
    "                  title='Train accuracy per number of '\n",
    "                        'sequences of stimulation:')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decoding stage\n",
    "\n",
    "Once the model is trained, we are ready to perform online decoding and evaluate\n",
    "its performance.\n",
    "\n",
    "First, we need to load the test recordings along with the true labels, which\n",
    "represent the commands the user was focusing on during this stage.\n",
    "\n",
    "Take into account that these recordings were also recorded in train mode to\n",
    "facilitate the assesment of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%% cd\n"
    }
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Parameter recordings is empty!",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[4], line 4\u001B[0m\n\u001B[0;32m      2\u001B[0m file_pattern \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124m*.rcp.bson\u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[0;32m      3\u001B[0m files \u001B[38;5;241m=\u001B[39m glob\u001B[38;5;241m.\u001B[39mglob(\u001B[38;5;124m'\u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;124m/\u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;124m'\u001B[39m \u001B[38;5;241m%\u001B[39m (folder, file_pattern))\n\u001B[1;32m----> 4\u001B[0m \u001B[43mdataset\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43madd_recordings\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfiles\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m      6\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mOK!\u001B[39m\u001B[38;5;124m'\u001B[39m)\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\medusa\\components.py:1055\u001B[0m, in \u001B[0;36mDataset.add_recordings\u001B[1;34m(self, recordings)\u001B[0m\n\u001B[0;32m   1053\u001B[0m recordings \u001B[38;5;241m=\u001B[39m [recordings] \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mtype\u001B[39m(recordings) \u001B[38;5;241m!=\u001B[39m \u001B[38;5;28mlist\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m recordings\n\u001B[0;32m   1054\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(recordings) \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[1;32m-> 1055\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mParameter recordings is empty!\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m   1056\u001B[0m \u001B[38;5;66;03m# Add recordings\u001B[39;00m\n\u001B[0;32m   1057\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m r \u001B[38;5;129;01min\u001B[39;00m recordings:\n\u001B[0;32m   1058\u001B[0m     \u001B[38;5;66;03m# Check if recording is instance of Recording of path\u001B[39;00m\n",
      "\u001B[1;31mValueError\u001B[0m: Parameter recordings is empty!"
     ]
    }
   ],
   "source": [
    "# Find test data\n",
    "print('> Loading test data...')\n",
    "file_pattern = '*TEST*.rcp.bson'\n",
    "test_files = glob.glob('%s/%s' % (folder, file_pattern))\n",
    "print('   - Detected %i test recordings' % len(test_files))\n",
    "\n",
    "# Create test dataset\n",
    "print('> Creating test dataset...')\n",
    "test_dataset = erp_spellers.ERPSpellerDataset(\n",
    "    channel_set=rec.eeg.channel_set,\n",
    "    fs=256,\n",
    "    biosignal_att_key='eeg',\n",
    "    experiment_att_key='erpspellerdata',\n",
    "    experiment_mode='train')\n",
    "test_dataset.add_recordings(test_files)\n",
    "\n",
    "# Test model\n",
    "print('> Test model with the test dataset')\n",
    "# Preprocessing\n",
    "signal = cmd_model.get_inst('prep_method').fit_transform_dataset(\n",
    "    test_dataset, test_dataset.fs)\n",
    "# Extract features\n",
    "x, x_info = cmd_model.get_inst('ext_method').transform_dataset(test_dataset)\n",
    "# Classification\n",
    "y_pred = cmd_model.get_inst('clf_method').predict_proba(x)[:, 1]\n",
    "# Command decoding\n",
    "spell_result, spell_result_per_seq, __ = erp_spellers.decode_commands(\n",
    "    scores=y_pred,\n",
    "    paradigm_conf=x_info['paradigm_conf'],\n",
    "    run_idx=x_info['run_idx'],\n",
    "    trial_idx=x_info['trial_idx'],\n",
    "    matrix_idx=x_info['matrix_idx'],\n",
    "    level_idx=x_info['level_idx'],\n",
    "    unit_idx=x_info['unit_idx'],\n",
    "    sequence_idx=x_info['sequence_idx'],\n",
    "    group_idx=x_info['group_idx'],\n",
    "    batch_idx=x_info['batch_idx']\n",
    ")\n",
    "# Assesment (possible because the recordings were recorded in train mode)\n",
    "spell_acc_per_seq = erp_spellers.command_decoding_accuracy_per_seq(\n",
    "    spell_result_per_seq,\n",
    "    x_info['spell_target']\n",
    ")\n",
    "# Print test results\n",
    "print_acc_per_seq(spell_acc_per_seq,\n",
    "                  title='Test accuracy per number of sequences of stimulation:')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "Check the following references for extended information about some of the\n",
    "aspects of this tutorial:\n",
    "\n",
    "1. *SantamarÃ­a-VÃ¡zquez, E., MartÃ­nez-Cagigal, V., Vaquerizo-Villar, F., &\n",
    "Hornero, R. (2020). EEG-Inception: A Novel Deep Convolutional Neural Network for\n",
    "Assistive ERP-based Brain-Computer Interfaces. IEEE Transactions on Neural\n",
    "Systems and Rehabilitation Engineering. DOI: __[https://doi.org/10.1109/TNSRE.2020.3048106](https://doi.org/10.1109/TNSRE.2020.3048106)__*\n",
    "2. *SantamarÃ­a-VÃ¡zquez, E., MartÃ­nez-Cagigal, V., Gomez-Pilar, J., & Hornero,\n",
    "R. (2019). Asynchronous Control of ERP-Based BCI Spellers Using Steady-State\n",
    "Visual Evoked Potentials Elicited by Peripheral Stimuli. IEEE Transactions on\n",
    "Neural Systems and Rehabilitation Engineering, 27(9), 1883-1892. DOI: __[https://doi.org/10.1109/tnsre.2019.2934645](https://doi.org/10.1109/tnsre.2019.2934645)__*\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}