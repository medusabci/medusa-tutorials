{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Welcome to the overview of medusa.bci.erp_spellers module!\n",
    "\n",
    "This module contains high level classes and functions specifically designed\n",
    "for ERP-based spellers. This notebook will cover the main features, functions\n",
    "and classes of the module through illustrative examples which will show you\n",
    "the power of the included tools.\n",
    "\n",
    "In this notebook you will learn:\n",
    "    - What is an ERP-based speller\n",
    "    - Download an open ERP-speller dataset and explore the files\n",
    "    - Create an instance of ERPSpellerDataset\n",
    "    - Know the feature extraction and decoding functions included in the module\n",
    "    - Implement an asynchronous ERP-based speller using the included models\n",
    "\n",
    "Do not forget to check the documentation if you do not understand something!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Introduction\n",
    "\n",
    "ERP-based spellers are\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports\n",
    "\n",
    "Import the modules that will be used in this notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "pycharm": {
     "name": "#%% cd\n"
    }
   },
   "outputs": [],
   "source": [
    "# General imports\n",
    "import glob\n",
    "from tabulate import tabulate\n",
    "import numpy as np\n",
    "\n",
    "# Medusa imports\n",
    "from medusa import components\n",
    "from medusa import meeg\n",
    "from medusa.bci import erp_spellers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download the dataset\n",
    "\n",
    "As strong supporters of open science, we have released and adapted some\n",
    "valuable datasets that can be very useful for researchers and practitioners.\n",
    "These datasets can be downloaded manually from www.medusa.com/datasets/ or\n",
    "using a simple API. In this case, we will use the API. Run the following cell\n",
    "to download the GIB-UVa ERP dataset [1].\n",
    "\n",
    "Each file is an instance of medusa.data_structures.Recording. This class\n",
    "contains the information of the performed experiment and the recorded biosignals\n",
    "In this case, the recordings contain an instance of\n",
    "medusa.components.ERPSpellerData, which is the default class for this\n",
    "experiment. Additionally, all recordings contain a medusa.meeg.EEG instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "pycharm": {
     "name": "#%% cd\n"
    }
   },
   "outputs": [],
   "source": [
    "# TODO: Download dataset\n",
    "# dataset_folder = os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## ERPSpellerDataset class\n",
    "\n",
    "This class is used to define an ERPSpeller dataset, which contains all the\n",
    "necessary information to work with the functions and classes of the module and\n",
    "checks for common errors.\n",
    "\n",
    "First, we have to define the channel set of the dataset. The signals added\n",
    "to the dataset will be adapted to this channel set, discarding the rest of EEG\n",
    "channels. In addition, the channels will be reordered if necessary. This\n",
    "avoids errors in heterogeneous datasets, and, believe me, saves tons of time\n",
    "wasted debugging machine learning algorithms. In this case, we will use 4 EEG\n",
    "channels: Fz, Cz, Pz, and Oz.\n",
    "\n",
    "We also have to define other parameters. The sample rate of the recordings\n",
    "is set to 256 Hz (if a file has different sample rate, it will throw  an error).\n",
    "We also define the keys to find the target biosignal (EEG) and experiment data\n",
    "(ERPSpellerData) attributes in the recording class, a well as the experiment\n",
    "mode, which is  set to train because we will use this dataset to train a\n",
    "model later. Check the documentation to understand the details of this and\n",
    "more parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "pycharm": {
     "name": "#%% cd\n"
    }
   },
   "outputs": [],
   "source": [
    "cha_set = meeg.EEGChannelSet()\n",
    "cha_set.set_standard_channels(l_cha=['Fz', 'Cz', 'Pz', 'Oz'])\n",
    "dataset = erp_spellers.ERPSpellerDataset(channel_set=cha_set,\n",
    "                                         fs=256,\n",
    "                                         biosignal_att_key='eeg',\n",
    "                                         experiment_att_key='erpspellerdata',\n",
    "                                         experiment_mode='train')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Add recordings to the dataset\n",
    "\n",
    "Now, we have to add the recordings to the dataset. With this purpose, we read\n",
    "the files that were downloaded and use the function add_recordings of our\n",
    "dataset. Note that this function admits instances of medusa.components.Recording\n",
    "or a list of paths. For convenience, we will use the second option in this case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "pycharm": {
     "name": "#%% cd\n"
    }
   },
   "outputs": [],
   "source": [
    "folder = 'data'\n",
    "file_pattern = '*.rcp.bson'\n",
    "files = glob.glob('%s/%s' % (folder, file_pattern))\n",
    "dataset.add_recordings(files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Explore some functions and classes\n",
    "\n",
    "Once we have defined our dataset, we can start to play! First, we extract\n",
    "ERP features using the class StandardFeatureExtraction with default parameters.\n",
    "This class extracts the EEG epochs after each stimulus onset\n",
    "\n",
    "Afterwards, we explore some decoding functions of the module, which translate\n",
    "epoch classification scores into commands,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "pycharm": {
     "name": "#%% cd\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Data exploration: \n",
      "\n",
      "----------  ----\n",
      "Runs           8\n",
      "Epochs      8640\n",
      "Target      1440\n",
      "Non-target  7200\n",
      "----------  ----\n",
      "\n",
      "Command decoding accuracy:\n",
      "\n",
      "All sequences: 97.92 %\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-18-ce8767b5cee0>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m     49\u001B[0m \u001B[0mtable_cmd_acc_per_seq\u001B[0m \u001B[1;33m+=\u001B[0m \u001B[0mcmd_acc_per_seq\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mtolist\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     50\u001B[0m \u001B[0mheaders\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;33m[\u001B[0m\u001B[1;34m''\u001B[0m\u001B[1;33m]\u001B[0m \u001B[1;33m+\u001B[0m \u001B[0mlist\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mrange\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;36m1\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;36m16\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 51\u001B[1;33m \u001B[0mprint\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mtabulate\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mtable_cmd_acc_per_seq\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mheaders\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mheaders\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     52\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m<ipython-input-18-ce8767b5cee0>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m     49\u001B[0m \u001B[0mtable_cmd_acc_per_seq\u001B[0m \u001B[1;33m+=\u001B[0m \u001B[0mcmd_acc_per_seq\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mtolist\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     50\u001B[0m \u001B[0mheaders\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;33m[\u001B[0m\u001B[1;34m''\u001B[0m\u001B[1;33m]\u001B[0m \u001B[1;33m+\u001B[0m \u001B[0mlist\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mrange\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;36m1\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;36m16\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 51\u001B[1;33m \u001B[0mprint\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mtabulate\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mtable_cmd_acc_per_seq\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mheaders\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mheaders\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     52\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m_pydevd_bundle\\pydevd_cython_win32_38_64.pyx\u001B[0m in \u001B[0;36m_pydevd_bundle.pydevd_cython_win32_38_64.SafeCallWrapper.__call__\u001B[1;34m()\u001B[0m\n",
      "\u001B[1;32m_pydevd_bundle\\pydevd_cython_win32_38_64.pyx\u001B[0m in \u001B[0;36m_pydevd_bundle.pydevd_cython_win32_38_64.PyDBFrame.trace_dispatch\u001B[1;34m()\u001B[0m\n",
      "\u001B[1;32m_pydevd_bundle\\pydevd_cython_win32_38_64.pyx\u001B[0m in \u001B[0;36m_pydevd_bundle.pydevd_cython_win32_38_64.PyDBFrame.trace_dispatch\u001B[1;34m()\u001B[0m\n",
      "\u001B[1;32m_pydevd_bundle\\pydevd_cython_win32_38_64.pyx\u001B[0m in \u001B[0;36m_pydevd_bundle.pydevd_cython_win32_38_64.PyDBFrame.trace_dispatch\u001B[1;34m()\u001B[0m\n",
      "\u001B[1;32mC:\\Programs\\JetBrains\\PyCharm 2020.2.3\\plugins\\python\\helpers-pro\\jupyter_debug\\pydev_jupyter_plugin.py\u001B[0m in \u001B[0;36mstop\u001B[1;34m(plugin, pydb, frame, event, args, stop_info, arg, step_cmd)\u001B[0m\n\u001B[0;32m    163\u001B[0m         \u001B[0mframe\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0msuspend_jupyter\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mmain_debugger\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mthread\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mframe\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mstep_cmd\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    164\u001B[0m         \u001B[1;32mif\u001B[0m \u001B[0mframe\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 165\u001B[1;33m             \u001B[0mmain_debugger\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mdo_wait_suspend\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mthread\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mframe\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mevent\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0marg\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    166\u001B[0m             \u001B[1;32mreturn\u001B[0m \u001B[1;32mTrue\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    167\u001B[0m     \u001B[1;32mreturn\u001B[0m \u001B[1;32mFalse\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mC:\\Programs\\JetBrains\\PyCharm 2020.2.3\\plugins\\python\\helpers\\pydev\\pydevd.py\u001B[0m in \u001B[0;36mdo_wait_suspend\u001B[1;34m(self, thread, frame, event, arg, send_suspend_message, is_unhandled_exception)\u001B[0m\n\u001B[0;32m   1145\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1146\u001B[0m         \u001B[1;32mwith\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_threads_suspended_single_notification\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mnotify_thread_suspended\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mthread_id\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mstop_reason\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1147\u001B[1;33m             \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_do_wait_suspend\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mthread\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mframe\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mevent\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0marg\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0msuspend_type\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mfrom_this_thread\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   1148\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1149\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0m_do_wait_suspend\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mthread\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mframe\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mevent\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0marg\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0msuspend_type\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mfrom_this_thread\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mC:\\Programs\\JetBrains\\PyCharm 2020.2.3\\plugins\\python\\helpers\\pydev\\pydevd.py\u001B[0m in \u001B[0;36m_do_wait_suspend\u001B[1;34m(self, thread, frame, event, arg, suspend_type, from_this_thread)\u001B[0m\n\u001B[0;32m   1160\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1161\u001B[0m                 \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mprocess_internal_commands\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1162\u001B[1;33m                 \u001B[0mtime\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0msleep\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;36m0.01\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   1163\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1164\u001B[0m         \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mcancel_async_evaluation\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mget_current_thread_id\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mthread\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mstr\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mid\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mframe\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "# Extract ERP features of the dataset using the transform_dataset of\n",
    "# StandardFeatureExtraction.\n",
    "feat_extractor = erp_spellers.StandardFeatureExtraction()\n",
    "x, x_info = feat_extractor.transform_dataset(dataset)\n",
    "\n",
    "# Print some info of the extracted features\n",
    "data_exploration = [\n",
    "    ['Runs', np.unique(x_info['run_idx']).shape[0]],\n",
    "    ['Epochs', x.shape[0]],\n",
    "    ['Target', np.sum(x_info['erp_labels']==1)],\n",
    "    ['Non-target', np.sum(x_info['erp_labels']==0)]\n",
    "]\n",
    "print('\\nData exploration: \\n')\n",
    "print(tabulate(data_exploration))\n",
    "\n",
    "# Check command decoding\n",
    "selected_commands, selected_commands_per_seq, cmd_scores = \\\n",
    "    erp_spellers.decode_commands(x_info['erp_labels'],\n",
    "                                 x_info['paradigm_conf'],\n",
    "                                 x_info['run_idx'],\n",
    "                                 x_info['trial_idx'],\n",
    "                                 x_info['matrix_idx'],\n",
    "                                 x_info['level_idx'],\n",
    "                                 x_info['unit_idx'],\n",
    "                                 x_info['sequence_idx'],\n",
    "                                 x_info['group_idx'],\n",
    "                                 x_info['batch_idx'])\n",
    "\n",
    "# Decode commands using the erp labels. This would give a 100% accuracy, but we\n",
    "# introduce error in trial 0 to check that everything works fine\n",
    "selected_commands[0][0][0][1] = 2\n",
    "cmd_acc = erp_spellers.command_decoding_accuracy(\n",
    "    selected_commands,\n",
    "    x_info['spell_target']\n",
    ")\n",
    "print('\\nCommand decoding accuracy:\\n')\n",
    "print('All sequences: %.2f %%' % (cmd_acc * 100))\n",
    "\n",
    "# Decode commands per number of sequences of stimulation using the erp labels.\n",
    "# This would give a 100% accuracy, but we introduce error in trial 0 sequence\n",
    "# 14 to check that everything works fine\n",
    "selected_commands_per_seq[0][0][0][14][1] = 2\n",
    "cmd_acc_per_seq = erp_spellers.command_decoding_accuracy_per_seq(\n",
    "    selected_commands_per_seq,\n",
    "    x_info['spell_target']\n",
    ")\n",
    "table_cmd_acc_per_seq = ['Command decoding accuracy']\n",
    "table_cmd_acc_per_seq += cmd_acc_per_seq.tolist()\n",
    "headers = [''] + list(range(1, 16))\n",
    "print(tabulate(table_cmd_acc_per_seq, headers=headers))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Command decoding model\n",
    "\n",
    "Although the previous functions are really powerful, and you can build your\n",
    "own EEG processing framework for ERP-based spellers easily with them, there is\n",
    "several built-in classes that combine them all to provide an easy-to-use model,\n",
    "ready to be used in your projects.\n",
    "\n",
    "In this tutorial, we will use some of the more powerful processing algorithms\n",
    "designed to date for each of the tasks. Take into account that models implement\n",
    "all the stages of the signal processing pipeline using the available functions\n",
    "in Medusa: (1) preprocessing, (2) feature extraction, (3) feature selection,\n",
    "(4) feature classification, and (5) command decoding. Concretely, we will use\n",
    "a deep convolutional neural network specifically designed for BCI applications:\n",
    "EEG-Inception. Check reference to understand all the details of this model [1].\n",
    "In order to continue with the tutorial, we recommend a python environment with\n",
    "the GPU version of tensorflow (v 2.0+) to reduce the training time. If you don't\n",
    "have access to this environment, don't worry, it will take only a few minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Instantiate ERPSpellerModel\n",
    "model = erp_spellers.CMDModelEEGInception()\n",
    "# Train model\n",
    "fit_results = model.fit_dataset(dataset)\n",
    "\n",
    "print('Train command decoding accuracy per sequence: %s' %\n",
    "      str(fit_results['spell_acc_per_seq']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Control state detection model\n",
    "\n",
    "There is one limitation that the previous model cannot solve. ERP-based spellers\n",
    "are, inherently, synchronous systems. They always make a selection even when the\n",
    "user is not attending to the stimuli. Nevertheless, this behaviour is not\n",
    "suitable for real applications, where an asynchronous operation is required.\n",
    "Do you imagine a web-browser based on an ERP-based speller in which you\n",
    "cannot read the web page you searched because the system keeps making\n",
    "selections?. Despite the futility of a synchronous system, most approaches to\n",
    "date do not address this issue. In order to achieve an asynchronous approach,\n",
    "we will need 2 types of models:\n",
    "\n",
    "    - Command decoding models (CMD): these models are in charge of the\n",
    "      command decoding task by detecting the ERPs within the EEG epochs to\n",
    "      decode the user's instentions. The previous model solves this task.\n",
    "    - Control state detection models (CSD): these models are in charge of the\n",
    "      control state detection task, which detects if users are attending the\n",
    "      stimuli or if they are engaged in other activities.\n",
    "\n",
    "It is important to understand that both models are necessary to build the\n",
    "complete signal processing pipeline of an ERP-based speller. Scientists have\n",
    "been traditionally focused in the first type. Nevertheless, an ERP-based speller\n",
    "is useless if it does not detect if the user is controlling the BCI application\n",
    "or is doing something else! Keep that in mind in your designs for real-life\n",
    "applications. In last years, we have worked to solve this issue, achieving quite\n",
    "a success. To know more about this problem and our work in the field, check\n",
    "references [2], [3] and [4].\n",
    "\n",
    "In ths tutorial we will use the class medusa.erp_spellers.CSDModelEEGInception\n",
    "to achieve an asynchronous ERP-based speller."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%% cd\n"
    }
   },
   "outputs": [],
   "source": [
    "# Instantiate ERPSpellerModel\n",
    "model = erp_spellers.CSDModelEEGInception()\n",
    "# Train model\n",
    "csd_fit_results = model.fit_dataset(dataset)\n",
    "\n",
    "print('Train control state accuracy per sequence: %s' %\n",
    "      str(csd_fit_results['control_state_acc_per_seq']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Conclusion\n",
    "\n",
    "That's all for now! Now you have a comprehensive picture of the functions and\n",
    "classes included in the module. As you can see, you can build the full signal\n",
    "processing pipeline of an ERP-based speller in few code lines using Medusa!\n",
    "\n",
    "See you in the next tutorial."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## References\n",
    "\n",
    "Check the following references for extended information about some of the\n",
    "aspects of this tutorial:\n",
    "\n",
    "1. Santamaría-Vázquez, E., Martínez-Cagigal, V., Vaquerizo-Villar, F., &\n",
    "Hornero, R. (2020). EEG-Inception: A Novel Deep Convolutional Neural Network for\n",
    "Assistive ERP-based Brain-Computer Interfaces. IEEE Transactions on Neural\n",
    "Systems and Rehabilitation Engineering.\n",
    "2. Santamaría-Vázquez, E., Martínez-Cagigal, V., Gomez-Pilar, J., & Hornero,\n",
    "R. (2019). Asynchronous Control of ERP-Based BCI Spellers Using Steady-State\n",
    "Visual Evoked Potentials Elicited by Peripheral Stimuli. IEEE Transactions on\n",
    "Neural Systems and Rehabilitation Engineering, 27(9), 1883-1892.\n",
    "3. Martínez-Cagigal, V., Santamaría-Vázquez, E., & Hornero, R. (2019). \n",
    "Asynchronous control of P300-based brain–computer interfaces using sample \n",
    "entropy. Entropy, 21(3), 230.\n",
    "4. XXX\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}