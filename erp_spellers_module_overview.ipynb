{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Welcome to the overview of medusa.bci.erp_spellers module!\n",
    "\n",
    "This module contains high level classes and functions specifically designed\n",
    "for ERP-based spellers. In this notebook, you will learn about the main\n",
    "features, function and classes of the module through illustrative examples\n",
    "which will show you the power of the included tools.\n",
    "\n",
    "In this notebook you will learn:\n",
    "    - What is an ERP-based speller\n",
    "    - Download an open ERP-speller dataset and explore the files\n",
    "    - Create an instance of ERPSpellerDataset\n",
    "    - Use important functions of the module\n",
    "    - Train and test an ERPModel class based on EEG-Inception\n",
    "    - Train and test a ControlStateModel class based on EEG-Inception\n",
    "\n",
    "Do not forget to check the documentation if you do not understand something!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Introduction\n",
    "\n",
    "ERP-based spellers are\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports\n",
    "\n",
    "Import the modules that will be used in this notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%% cd\n"
    }
   },
   "outputs": [],
   "source": [
    "from medusa import meeg_standards\n",
    "from medusa import data_structures\n",
    "from medusa.bci import erp_spellers\n",
    "import glob, os\n",
    "from tabulate import tabulate\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download the dataset\n",
    "\n",
    "As strong supporters of open science, we have released and adapted some\n",
    "valuable datasets that can be very useful for researchers and practitioners.\n",
    "These datasets can be downloaded manually from www.medusa.com/datasets/ or\n",
    "using a simple API. In this case, we will use the API. Run the following cell\n",
    "to download the GIB-UVa ERP dataset [1].\n",
    "\n",
    "Each file is an instance of medusa.data_structures.Recording. This class\n",
    "contains the information of the performed experiment and the registered\n",
    "biosignals. In this case, we will assume that the recording contains an\n",
    "instance of medusa.data_structures.ERPSpellerData, which is the default class\n",
    "for this experiment. Additionally, the recording must contain a\n",
    "medusa.data_structures.EEG instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%% cd\n"
    }
   },
   "outputs": [],
   "source": [
    "# TODO: Download dataset\n",
    "# dataset_folder = os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## ERPSpellerDataset class\n",
    "\n",
    "This class is used to define an ERPSpeller dataset, which contains all the\n",
    "necessary information to work with the functions and classes of the module and\n",
    "checks for common errors.\n",
    "\n",
    "First, we have to define the channel set of the dataset. The signals added\n",
    "to the dataset will be adapted to this channel set, discarding the rest of EEG\n",
    "channels. In addition, the channels will be reordered if necessary. This\n",
    "avoids errors in heterogeneous datasets, and, believe me, saves tons of time\n",
    "wasted debugging machine learning algorithms. In this case, we will use 4 EEG\n",
    "channels: Fz, Cz, Pz, and Oz.\n",
    "\n",
    "We also have to define other parameters. The sample rate of the recordings\n",
    "is set to 256 Hz (if a file has different sample rate, it will throw  an error).\n",
    "We also define the keys to find the target biosignal (EEG) and experiment data\n",
    "(ERPSpellerData) attributes in the recording class, a well as the experiment\n",
    "mode, which is  set to train because we will use this dataset to train a\n",
    "model later. Check the documentation to understand the details of this and\n",
    "more parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%% cd\n"
    }
   },
   "outputs": [],
   "source": [
    "cha_set = meeg_standards.EEGChannelSet()\n",
    "cha_set.set_standard_channels(l_cha=['Fz', 'Cz', 'Pz', 'Oz'])\n",
    "dataset = erp_spellers.ERPSpellerDataset(channel_set=cha_set,\n",
    "                                         fs=256,\n",
    "                                         biosignal_att_key='eeg',\n",
    "                                         experiment_att_key='erpspellerdata',\n",
    "                                         experiment_mode='train')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Add recordings to the dataset\n",
    "\n",
    "Now, we have to add the recordings to the dataset. With this purpose, we read\n",
    "the files that were downloaded and use the function add_recordingsof our\n",
    "dataset. Note that this function admits instances of\n",
    "medusa.data_structures.Recording or a list of paths. For convinience, we will\n",
    " use the second option in this case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%% cd\n"
    }
   },
   "outputs": [],
   "source": [
    "folder = 'E:/Eduardo/PythonProjects/medusa/medusa-platform/data'\n",
    "file_pattern = '*.rcp.bson'\n",
    "files = glob.glob('%s/%s' % (folder, file_pattern))\n",
    "dataset.add_recordings(files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Explore some functions and classes\n",
    "\n",
    "Once we have defined our dataset, we can start to play! First, we extract the\n",
    "ERP features using the function extract_erp_features_from_dataset. This function\n",
    "returns the ERP epochs, and a variable which keeps track of all the useful\n",
    "information that allow command decoding and control state detection. Check\n",
    "the documentation of ERPSpellerData to know the meaning of each of these\n",
    "variables. Afterwards, we simulate the scores of a classifier using the\n",
    "labels to check  the decoding  functions. Thus, we expect 100% accuracy for\n",
    "command decoding and control  state detection tasks. However, we introduced\n",
    "some errors to check that  everything works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "pycharm": {
     "name": "#%% cd\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Data exploration: \n",
      "\n",
      "----------  ----\n",
      "Runs           4\n",
      "Epochs      4320\n",
      "Target       720\n",
      "Non-target  3600\n",
      "----------  ----\n",
      "\n",
      "Command decoding accuracy:\n",
      "\n",
      "All sequences: 95.83 %\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'float' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-30-485bb69ae2f8>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m     43\u001B[0m \u001B[0mtable_cmd_acc_per_seq\u001B[0m \u001B[1;33m+=\u001B[0m \u001B[0mcmd_acc_per_seq\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mtolist\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     44\u001B[0m \u001B[0mheaders\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;33m[\u001B[0m\u001B[1;34m''\u001B[0m\u001B[1;33m]\u001B[0m \u001B[1;33m+\u001B[0m \u001B[0mnp\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0marange\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;36m1\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;36m16\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mtolist\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 45\u001B[1;33m \u001B[0mprint\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mtabulate\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mtable_cmd_acc_per_seq\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mheaders\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mheaders\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[1;32mE:\\Programs\\Anaconda\\envs\\medusa\\lib\\site-packages\\tabulate.py\u001B[0m in \u001B[0;36mtabulate\u001B[1;34m(tabular_data, headers, tablefmt, floatfmt, numalign, stralign, missingval, showindex, disable_numparse, colalign)\u001B[0m\n\u001B[0;32m   1527\u001B[0m         \u001B[0mtabular_data\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;33m[\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1528\u001B[0m     list_of_lists, headers = _normalize_tabular_data(\n\u001B[1;32m-> 1529\u001B[1;33m         \u001B[0mtabular_data\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mheaders\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mshowindex\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mshowindex\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   1530\u001B[0m     )\n\u001B[0;32m   1531\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mE:\\Programs\\Anaconda\\envs\\medusa\\lib\\site-packages\\tabulate.py\u001B[0m in \u001B[0;36m_normalize_tabular_data\u001B[1;34m(tabular_data, headers, showindex)\u001B[0m\n\u001B[0;32m   1189\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1190\u001B[0m     \u001B[0mheaders\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mlist\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mmap\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0m_text_type\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mheaders\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1191\u001B[1;33m     \u001B[0mrows\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mlist\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mmap\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mlist\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mrows\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   1192\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1193\u001B[0m     \u001B[1;31m# add or remove an index column\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mTypeError\u001B[0m: 'float' object is not iterable"
     ]
    }
   ],
   "source": [
    "# Extract ERP features\n",
    "features, track_info = erp_spellers.extract_erp_features_from_dataset(dataset)\n",
    "\n",
    "data_exploration = [\n",
    "    ['Runs', np.unique(track_info['run_idx']).shape[0]],\n",
    "    ['Epochs', features.shape[0]],\n",
    "    ['Target', np.sum(track_info['erp_labels']==1)],\n",
    "    ['Non-target', np.sum(track_info['erp_labels']==0)]\n",
    "]\n",
    "print('\\nData exploration: \\n')\n",
    "print(tabulate(data_exploration))\n",
    "\n",
    "# Check command decoding\n",
    "selected_commands, selected_commands_per_seq, cmd_scores = \\\n",
    "    erp_spellers.decode_commands(track_info['erp_labels'],\n",
    "                                 track_info['paradigm_conf'],\n",
    "                                 track_info['run_idx'],\n",
    "                                 track_info['trial_idx'],\n",
    "                                 track_info['matrix_idx'],\n",
    "                                 track_info['level_idx'],\n",
    "                                 track_info['unit_idx'],\n",
    "                                 track_info['sequence_idx'],\n",
    "                                 track_info['group_idx'],\n",
    "                                 track_info['batch_idx'])\n",
    "\n",
    "# Introduce error in trial 0 and check accuracy\n",
    "selected_commands[0][0][0][1] = 2\n",
    "cmd_acc = erp_spellers.command_decoding_accuracy(\n",
    "    selected_commands,\n",
    "    track_info['spell_target']\n",
    ")\n",
    "print('\\nCommand decoding accuracy:\\n')\n",
    "print('All sequences: %.2f %%' % (cmd_acc * 100))\n",
    "\n",
    "# Introduce error in trial 0 sequence 14 and check accuracy\n",
    "selected_commands_per_seq[0][0][0][14][1] = 2\n",
    "cmd_acc_per_seq = erp_spellers.command_decoding_accuracy_per_seq(\n",
    "    selected_commands_per_seq,\n",
    "    track_info['spell_target']\n",
    ")\n",
    "\n",
    "table_cmd_acc_per_seq = ['Command decoding accuracy']\n",
    "table_cmd_acc_per_seq += cmd_acc_per_seq.tolist()\n",
    "headers = [''] + np.arange(1, 16).tolist()\n",
    "print(tabulate(table_cmd_acc_per_seq, headers=headers))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## ERP speller processing pipeline\n",
    "\n",
    "Although the previous functions are really powerful, and you can build your\n",
    "own EEG processing framework for ERP-based spellers easily with them, there is\n",
    "1 class that combines them all to provide an easy-to-use model, ready to be\n",
    "used in your projects.\n",
    "\n",
    "The class ERPModel implements the functions used to control an ERP-based\n",
    "speller. In other words, it provides the synchronous control of the speller,\n",
    "implementing all the stages: (1) preprocessing, (2) feature extraction,\n",
    "(3) feature selection, (4) feature classification, and (5) command decoding.\n",
    "Currently, it supports 2 classifiers: regularized linear discriminant analysis\n",
    "(rLDA), and EEG-Inception, each of them requiring different parameters in the\n",
    " preprocessing, feature extraction and feature selection stages.\n",
    "\n",
    "In this tutorial, we will implement a model based on EEG-Inception. By\n",
    "default, ERPModelSettings are prepared to use this classifier, since it is more\n",
    "powerful than rLDA [1]. Nevertheless, rLDA may be adequate in some cases, as it\n",
    "trains faster (especially when no graphic card is available) and requires\n",
    "less computational resources. Check the documentation to learn how to use\n",
    "ERPModelSettings to change between the supported models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Instantiate ERPModelSettings and print the summary\n",
    "settings = erp_spellers.ERPModelSettings()\n",
    "settings.summary()\n",
    "\n",
    "# Instantiate ERPSpellerModel\n",
    "model = erp_spellers.ERPSpellerModel()\n",
    "model.configure(settings)\n",
    "# Train model\n",
    "spell_target, spell_result_per_seq, spell_acc_per_seq = \\\n",
    "    model.fit_dataset(dataset)\n",
    "\n",
    "print('Train command decoding accuracy per sequence: %s' %\n",
    "      str(spell_acc_per_seq))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## CSDModel class\n",
    "\n",
    "There is one limitation that ERPModel cannot solve. ERP-based spellers are,\n",
    "inherently, synchronous systems. They always make a selection even when the\n",
    "user is not attending to the stimuli. Nevertheless, this behaviour is not\n",
    "suitable for real applications, where an asynchronous operation is required.\n",
    "Do you imagine a web-browser based on an ERP-based speller in which you\n",
    "cannot read the web page you searched because the system keeps presenting\n",
    "stimuli?. Despite the futility of a synchronous system, most approaches to\n",
    "date do not address this issue. In last years, we have worked in it,\n",
    "achieving quite a success. To know more about this problem and our work in\n",
    "the field, check references [2], [3] and [4].\n",
    "\n",
    "The class ERPModel implements the functions used to control an ERP-based\n",
    "speller. In other words, it provides the synchronous control of the speller,\n",
    "implementing all the stages: (1) preprocessing, (2) feature extraction,\n",
    "(3) feature selection, (4) feature classification, and (5) command decoding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%% cd\n"
    }
   },
   "outputs": [],
   "source": [
    "# Instantiate ERPModelSettings and print the summary\n",
    "settings = erp_spellers.ERPModelSettings()\n",
    "settings.summary()\n",
    "\n",
    "# Instantiate ERPSpellerModel\n",
    "model = erp_spellers.ERPSpellerModel()\n",
    "model.configure(settings)\n",
    "# Train model\n",
    "cs_target, cs_result_per_seq, cs_acc_per_seq = model.fit_dataset(dataset)\n",
    "\n",
    "print('Train control state accuracy per sequence: %s' % str(cs_acc_per_seq))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Conclusion\n",
    "\n",
    "That's all for now! Now you have a comprehensive picture of the functions and\n",
    "classes included in the module. As you can see, you can build the full signal\n",
    "processing pipeline of an ERP-based speller in few code lines using Medusa!\n",
    "\n",
    "See you in the next tutorial."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## References\n",
    "\n",
    "Check the following references for extended information about some of the\n",
    "aspects of this tutorial:\n",
    "\n",
    "1. Santamaría-Vázquez, E., Martínez-Cagigal, V., Vaquerizo-Villar, F., &\n",
    "Hornero, R. (2020). EEG-Inception: A Novel Deep Convolutional Neural Network for\n",
    "Assistive ERP-based Brain-Computer Interfaces. IEEE Transactions on Neural\n",
    "Systems and Rehabilitation Engineering.\n",
    "2. Santamaría-Vázquez, E., Martínez-Cagigal, V., Gomez-Pilar, J., & Hornero,\n",
    "R. (2019). Asynchronous Control of ERP-Based BCI Spellers Using Steady-State\n",
    "Visual Evoked Potentials Elicited by Peripheral Stimuli. IEEE Transactions on\n",
    "Neural Systems and Rehabilitation Engineering, 27(9), 1883-1892.\n",
    "3. Martínez-Cagigal, V., Santamaría-Vázquez, E., & Hornero, R. (2019). \n",
    "Asynchronous control of P300-based brain–computer interfaces using sample \n",
    "entropy. Entropy, 21(3), 230.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}